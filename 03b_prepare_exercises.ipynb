{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71030dcc",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f24ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import acquire\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "from time import strftime\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b60bd",
   "metadata": {},
   "source": [
    "## 1. `basic_clean` function\n",
    "This function should take in a string and apply some basic text cleaning to it:\n",
    "1. Lowercase everything,\n",
    "2. Normalize unicode characters, and\n",
    "3. Replace anything that is not a letter, number, whitespace or a single quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b6e607c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncarrot cake brownie carrot cake ice cream croissant powder bear claw icing tiramisu souffle fruitcake carrot \\ncake macaroon liquorice dragee sweet icing lollipop chocolate bar jelly beans\\ncake sugar plum cookie tiramisu dessert cupcake sweet lollipop liquorice dragee ice cream pastry shortbread \\nhalvah chupa chups sweet ice cream cheesecake pastry powder donut cake\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. lowercase\n",
    "string = '''\n",
    "Carrot cake brownie carrot cake ice cream croissant powder bear claw. Icing tiramisu soufflé fruitcake carrot \n",
    "cake macaroon liquorice. Dragée sweet icing lollipop chocolate bar jelly beans.\n",
    "Cake sugar plum cookie tiramisu dessert cupcake sweet lollipop liquorice. Dragée ice cream pastry shortbread \n",
    "halvah chupa chups sweet ice cream. Cheesecake pastry powder donut cake.\n",
    "'''.lower()#.strip().lower()\n",
    "\n",
    "# 2. normalize unicode\n",
    "string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "# 3. replace non-alphanumeric characters\n",
    "string = re.sub(r\"[^a-z0-9'\\s]\", '', string)#.replace('\\n', ' ')\n",
    "\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1553c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string as a paramenter and performs the following basic cleaning functions:\n",
    "        1. lowercase,\n",
    "        2. normalize unicode, and\n",
    "        3. remove non-alphanumeric characters\n",
    "    \n",
    "    The function returns the cleaned string.\n",
    "    '''\n",
    "    # 1. lowercase\n",
    "    string = string.strip().lower()\n",
    "    \n",
    "    # 2. normalize unicode\n",
    "    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "    # 3. replace non-alphanumeric characters\n",
    "    string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c51f1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"9po6ykrq \\x0cv3tu\\n7ig'kots64saio'k\\njmnrilyetqams63f\\nh821e83qyw69emer\\nrsvbl72qzfmv33bmu\\n7p 7ditjdzjpr9sicm\\nqvadpsz7vuwglvx\\nn1trtuweit5pq8j0q7o\\nrls9dozscruop8m\\nnz8lrcfvksubhd2d'\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tesitng the function\n",
    "basic_clean(\"\"\"\n",
    "-9p]o.6ykrq` \\14v3tu\n",
    "7ig'kots64s[ai.o'[k/\n",
    "jmnr/;ilyetqams6/;3f\n",
    "h821\\e83qyw69eme.;r,\n",
    "rsvb,l72qzfmv33bm,u=\n",
    "7p 7ditj\\dzjpr9s=icm\n",
    "qva,d],p;sz7vu[wglvx\n",
    "n1trtu;weit5pq8j0q7o\n",
    "rls9dozsc`ruop8m.-\\0\n",
    "nz8lr=cfvksu/bhd-2d'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ccacc5",
   "metadata": {},
   "source": [
    "## 2. `tokenize` function\n",
    "This function should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ab3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"\n",
    "-9p]o.6ykrq` \\14v3tu\n",
    "7ig'kots64s[ai.o'[k/\n",
    "jmnr/;ilyetqams6/;3f\n",
    "h821\\e83qyw69eme.;r,\n",
    "rsvb,l72qzfmv33bm,u=\n",
    "7p 7ditj\\dzjpr9s=icm\n",
    "qva,d],p;sz7vu[wglvx\n",
    "n1trtu;weit5pq8j0q7o\n",
    "rls9dozsc`ruop8m.-\\0\n",
    "nz8lr=cfvksu/bhd-2d'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f8e8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"-9p ] o.6ykrq ` \\x0cv3tu\\n7ig ' kots64s[ ai.o ' [ k/\\njmnr/ ; ilyetqams6/ ; 3f\\nh821\\\\e83qyw69eme. ; r , \\nrsvb , l72qzfmv33bm , u=\\n7p 7ditj\\\\dzjpr9s=icm\\nqva , d ] , p ; sz7vu[ wglvx\\nn1trtu ; weit5pq8j0q7o\\nrls9dozsc ` ruop8m.-\\x00\\nnz8lr=cfvksu/bhd-2d '\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "tokenizer.tokenize(test_string, return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d47f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and returns the tokenized version of that string.\n",
    "    '''\n",
    "    \n",
    "    # creating tokenizer object\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # using tokenizer object on string\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d1a91d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is a string. Let ' s see what happens when we tokenize it !\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('''\n",
    "This is a string. Let's see what happens when we tokenize it!\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39150046",
   "metadata": {},
   "source": [
    "## 3. `stem` function\n",
    "This function should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4086e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string, stems each individual word, and then joins\n",
    "    the stem words back together in the returned string.\n",
    "    '''\n",
    "    \n",
    "    # creating the stem object\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # creating the stems for each individual word in the string\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    # putting the stemmed words back together into string\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd538ce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'carrot cake browni carrot cake ice cream croissant powder bear claw ice tiramisu souffl fruitcak carrot cake macaroon liquoric drage sweet ice lollipop chocol bar jelli bean cake sugar plum cooki tiramisu dessert cupcak sweet lollipop liquoric drage ice cream pastri shortbread halvah chupa chup sweet ice cream cheesecak pastri powder donut cake'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c759c7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cake      5\n",
       "cream     3\n",
       "carrot    3\n",
       "sweet     3\n",
       "ice       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(string.split()).value_counts().head(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0dbbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6062595",
   "metadata": {},
   "source": [
    "## 4. `lemmatize` function\n",
    "This function should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a9afb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # create the lemmatization object\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # creating a list of string of each word in the article and applying the lemmatize object to each word\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # joining the individual list of lemma string words to a single string of words\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e22abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'carrot cake brownie carrot cake ice cream croissant powder bear claw icing tiramisu souffle fruitcake carrot cake macaroon liquorice dragee sweet icing lollipop chocolate bar jelly bean cake sugar plum cookie tiramisu dessert cupcake sweet lollipop liquorice dragee ice cream pastry shortbread halvah chupa chups sweet ice cream cheesecake pastry powder donut cake'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6317e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncarrot cake brownie carrot cake ice cream croissant powder bear claw icing tiramisu souffle fruitcake carrot \\ncake macaroon liquorice dragee sweet icing lollipop chocolate bar jelly beans\\ncake sugar plum cookie tiramisu dessert cupcake sweet lollipop liquorice dragee ice cream pastry shortbread \\nhalvah chupa chups sweet ice cream cheesecake pastry powder donut cake\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233de91a",
   "metadata": {},
   "source": [
    "## 5. `remove_stopwords`\n",
    "This function should accept some text and return the text after removing all the stopwords.\n",
    "<br>\n",
    "It should also define two parameters:\n",
    "- `extra-words` any additional stop words (words we want removed that are not already listed as stop words)\n",
    "- `exclude-words` any words you want excluded from stop words search (stop words we don't want removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "934f7b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calls a list of common english stopwords\n",
    "stopwords.words('english')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeee84c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary', 'little', 'lamb.', 'Little', 'lamb.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the list of english stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "# savings the words in the string as a list of strings for each indidvidual word\n",
    "words = 'Mary had a little lamb. Little lamb.'.split()\n",
    "\n",
    "# creating a for loop that will loop through each of the individual words in the string\n",
    "#     and return a list of only the words that are not in the list of stopwords\n",
    "[word for word in words \\\n",
    "    if word not in stopword_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4023c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in a string of words and splits it into a list of strings for each individual \n",
    "    word. It then loops through the list of words and returns a string of the joined string words, \n",
    "    excluding the stopwords.\n",
    "    '''\n",
    "    \n",
    "    # splitting the string of words into a list of strings\n",
    "    words = string.split()\n",
    "    \n",
    "    # saving the stop words\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # looping through the list of words and creating a new list with the words not in the stopwords list\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # joining the list of words back to a string of words\n",
    "    filtered_string = ' '.join(filtered_words)\n",
    "    \n",
    "    # printing number of words removed\n",
    "    print(f'Removed {len(string) - len(filtered_string)} stop words.\\n> Original string: {len(string)}\\n> New string: {len(filtered_string)}')\n",
    "    print()\n",
    "    \n",
    "    return filtered_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eae6608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 18 stop words.\n",
      "> Original string: 95\n",
      "> New string: 77\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This little light mine, I\"m going let shine. Let shine, let shine, let shine.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing function\n",
    "remove_stopwords('This little light of mine, I\"m going to let it shine. Let it shine, let it shine, let it shine.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fd81b",
   "metadata": {},
   "source": [
    "## 6. `news_df`\n",
    "Use your data from the acquire to produce a dataframe of the news articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee937359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIC files draft papers with SEBI to seek appro...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>State-run Life Insurance Corporation of India ...</td>\n",
       "      <td>13 Feb 2022,Sunday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have lost a visionary: Rahul Gandhi on Rahu...</td>\n",
       "      <td>Shalini Ojha</td>\n",
       "      <td>Former Congress chief Rahul Gandhi condoled th...</td>\n",
       "      <td>12 Feb 2022,Saturday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piyush Goyal shares meme featuring Shark Tank'...</td>\n",
       "      <td>Apaar Sharma</td>\n",
       "      <td>Union Minister Piyush Goyal has shared a Shark...</td>\n",
       "      <td>13 Feb 2022,Sunday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've made multi-billion dollar businesses, it ...</td>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>Speaking on Figuring Out podcast, BharatPe Co-...</td>\n",
       "      <td>12 Feb 2022,Saturday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13-yr-old girl gets ₹50 lakh funding on Shark ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>A Class 8 girl became the youngest contestant ...</td>\n",
       "      <td>13 Feb 2022,Sunday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          author  \\\n",
       "0  LIC files draft papers with SEBI to seek appro...  Pragya Swastik   \n",
       "1  We have lost a visionary: Rahul Gandhi on Rahu...    Shalini Ojha   \n",
       "2  Piyush Goyal shares meme featuring Shark Tank'...    Apaar Sharma   \n",
       "3  I've made multi-billion dollar businesses, it ...     Daisy Mowke   \n",
       "4  13-yr-old girl gets ₹50 lakh funding on Shark ...  Ridham Gambhir   \n",
       "\n",
       "                                             content                  date  \\\n",
       "0  State-run Life Insurance Corporation of India ...    13 Feb 2022,Sunday   \n",
       "1  Former Congress chief Rahul Gandhi condoled th...  12 Feb 2022,Saturday   \n",
       "2  Union Minister Piyush Goyal has shared a Shark...    13 Feb 2022,Sunday   \n",
       "3  Speaking on Figuring Out podcast, BharatPe Co-...  12 Feb 2022,Saturday   \n",
       "4  A Class 8 girl became the youngest contestant ...    13 Feb 2022,Sunday   \n",
       "\n",
       "   category  \n",
       "0  business  \n",
       "1  business  \n",
       "2  business  \n",
       "3  business  \n",
       "4  business  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inshorts = acquire.get_inshorts_articles()\n",
    "inshorts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93a156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec83a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef519b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42ac1227",
   "metadata": {},
   "source": [
    "## 7. `codeup_df`\n",
    "Make another dataframe from the codeup blog posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d796edca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup Dallas Open House</td>\n",
       "      <td>Nov 30, 2021</td>\n",
       "      <td>Come join us for the re-opening of our Dallas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Codeup’s Placement Team Continues Setting Records</td>\n",
       "      <td>Nov 19, 2021</td>\n",
       "      <td>Our Placement Team is simply defined as a grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT Certifications 101: Why They Matter, and Wh...</td>\n",
       "      <td>Nov 18, 2021</td>\n",
       "      <td>AWS, Google, Azure, Red Hat, CompTIA…these are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A rise in cyber attacks means opportunities fo...</td>\n",
       "      <td>Nov 17, 2021</td>\n",
       "      <td>In the last few months, the US has experienced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Use your GI Bill® benefits to Land a Job in Tech</td>\n",
       "      <td>Nov 4, 2021</td>\n",
       "      <td>As the end of military service gets closer, ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     published  \\\n",
       "0                           Codeup Dallas Open House  Nov 30, 2021   \n",
       "1  Codeup’s Placement Team Continues Setting Records  Nov 19, 2021   \n",
       "2  IT Certifications 101: Why They Matter, and Wh...  Nov 18, 2021   \n",
       "3  A rise in cyber attacks means opportunities fo...  Nov 17, 2021   \n",
       "4   Use your GI Bill® benefits to Land a Job in Tech   Nov 4, 2021   \n",
       "\n",
       "                                             content  \n",
       "0  Come join us for the re-opening of our Dallas ...  \n",
       "1  Our Placement Team is simply defined as a grou...  \n",
       "2  AWS, Google, Azure, Red Hat, CompTIA…these are...  \n",
       "3  In the last few months, the US has experienced...  \n",
       "4  As the end of military service gets closer, ma...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_blogs = acquire.get_blog_articles()\n",
    "codeup_blogs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e8d3e",
   "metadata": {},
   "source": [
    "## 8. DataFrame columns\n",
    "For each dataframe, produce the following columns:\n",
    "- `title` to hold the title\n",
    "- `original` to hold the original article/post content\n",
    "- `clean` to hold the normalized and tokenized original with the stopwords removed.\n",
    "- `stemmed` to hold the stemmed version of the cleaned data.\n",
    "- `lemmatized` to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56a54b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIC files draft papers with SEBI to seek appro...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>State-run Life Insurance Corporation of India ...</td>\n",
       "      <td>13 Feb 2022,Sunday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have lost a visionary: Rahul Gandhi on Rahu...</td>\n",
       "      <td>Shalini Ojha</td>\n",
       "      <td>Former Congress chief Rahul Gandhi condoled th...</td>\n",
       "      <td>12 Feb 2022,Saturday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piyush Goyal shares meme featuring Shark Tank'...</td>\n",
       "      <td>Apaar Sharma</td>\n",
       "      <td>Union Minister Piyush Goyal has shared a Shark...</td>\n",
       "      <td>13 Feb 2022,Sunday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've made multi-billion dollar businesses, it ...</td>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>Speaking on Figuring Out podcast, BharatPe Co-...</td>\n",
       "      <td>12 Feb 2022,Saturday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13-yr-old girl gets ₹50 lakh funding on Shark ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>A Class 8 girl became the youngest contestant ...</td>\n",
       "      <td>13 Feb 2022,Sunday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          author  \\\n",
       "0  LIC files draft papers with SEBI to seek appro...  Pragya Swastik   \n",
       "1  We have lost a visionary: Rahul Gandhi on Rahu...    Shalini Ojha   \n",
       "2  Piyush Goyal shares meme featuring Shark Tank'...    Apaar Sharma   \n",
       "3  I've made multi-billion dollar businesses, it ...     Daisy Mowke   \n",
       "4  13-yr-old girl gets ₹50 lakh funding on Shark ...  Ridham Gambhir   \n",
       "\n",
       "                                             content                  date  \\\n",
       "0  State-run Life Insurance Corporation of India ...    13 Feb 2022,Sunday   \n",
       "1  Former Congress chief Rahul Gandhi condoled th...  12 Feb 2022,Saturday   \n",
       "2  Union Minister Piyush Goyal has shared a Shark...    13 Feb 2022,Sunday   \n",
       "3  Speaking on Figuring Out podcast, BharatPe Co-...  12 Feb 2022,Saturday   \n",
       "4  A Class 8 girl became the youngest contestant ...    13 Feb 2022,Sunday   \n",
       "\n",
       "   category  \n",
       "0  business  \n",
       "1  business  \n",
       "2  business  \n",
       "3  business  \n",
       "4  business  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inshorts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39c89974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIC files draft papers with SEBI to seek appro...</td>\n",
       "      <td>State-run Life Insurance Corporation of India ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have lost a visionary: Rahul Gandhi on Rahu...</td>\n",
       "      <td>Former Congress chief Rahul Gandhi condoled th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piyush Goyal shares meme featuring Shark Tank'...</td>\n",
       "      <td>Union Minister Piyush Goyal has shared a Shark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've made multi-billion dollar businesses, it ...</td>\n",
       "      <td>Speaking on Figuring Out podcast, BharatPe Co-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13-yr-old girl gets ₹50 lakh funding on Shark ...</td>\n",
       "      <td>A Class 8 girl became the youngest contestant ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LIC files draft papers with SEBI to seek appro...   \n",
       "1  We have lost a visionary: Rahul Gandhi on Rahu...   \n",
       "2  Piyush Goyal shares meme featuring Shark Tank'...   \n",
       "3  I've made multi-billion dollar businesses, it ...   \n",
       "4  13-yr-old girl gets ₹50 lakh funding on Shark ...   \n",
       "\n",
       "                                            original  \n",
       "0  State-run Life Insurance Corporation of India ...  \n",
       "1  Former Congress chief Rahul Gandhi condoled th...  \n",
       "2  Union Minister Piyush Goyal has shared a Shark...  \n",
       "3  Speaking on Figuring Out podcast, BharatPe Co-...  \n",
       "4  A Class 8 girl became the youngest contestant ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = inshorts[['title', 'content']].rename(columns = {'content': 'original'})\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "756794e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding clean column\n",
    "news['clean'] = news.original.apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd13fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding stem column\n",
    "news['stemmed'] = news.clean.apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abc920aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding lemmatized column (from clean column)\n",
    "news['lemmatized'] = news.clean.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8db82f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIC files draft papers with SEBI to seek appro...</td>\n",
       "      <td>State-run Life Insurance Corporation of India ...</td>\n",
       "      <td>staterun life insurance corporation of india l...</td>\n",
       "      <td>staterun life insur corpor of india lic on sun...</td>\n",
       "      <td>staterun life insurance corporation of india l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have lost a visionary: Rahul Gandhi on Rahu...</td>\n",
       "      <td>Former Congress chief Rahul Gandhi condoled th...</td>\n",
       "      <td>former congress chief rahul gandhi condoled th...</td>\n",
       "      <td>former congress chief rahul gandhi condol the ...</td>\n",
       "      <td>former congress chief rahul gandhi condoled th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piyush Goyal shares meme featuring Shark Tank'...</td>\n",
       "      <td>Union Minister Piyush Goyal has shared a Shark...</td>\n",
       "      <td>union minister piyush goyal has shared a shark...</td>\n",
       "      <td>union minist piyush goyal ha share a shark tan...</td>\n",
       "      <td>union minister piyush goyal ha shared a shark ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've made multi-billion dollar businesses, it ...</td>\n",
       "      <td>Speaking on Figuring Out podcast, BharatPe Co-...</td>\n",
       "      <td>speaking on figuring out podcast bharatpe cofo...</td>\n",
       "      <td>speak on figur out podcast bharatp cofound ash...</td>\n",
       "      <td>speaking on figuring out podcast bharatpe cofo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13-yr-old girl gets ₹50 lakh funding on Shark ...</td>\n",
       "      <td>A Class 8 girl became the youngest contestant ...</td>\n",
       "      <td>a class 8 girl became the youngest contestant ...</td>\n",
       "      <td>a class 8 girl becam the youngest contest to p...</td>\n",
       "      <td>a class 8 girl became the youngest contestant ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LIC files draft papers with SEBI to seek appro...   \n",
       "1  We have lost a visionary: Rahul Gandhi on Rahu...   \n",
       "2  Piyush Goyal shares meme featuring Shark Tank'...   \n",
       "3  I've made multi-billion dollar businesses, it ...   \n",
       "4  13-yr-old girl gets ₹50 lakh funding on Shark ...   \n",
       "\n",
       "                                            original  \\\n",
       "0  State-run Life Insurance Corporation of India ...   \n",
       "1  Former Congress chief Rahul Gandhi condoled th...   \n",
       "2  Union Minister Piyush Goyal has shared a Shark...   \n",
       "3  Speaking on Figuring Out podcast, BharatPe Co-...   \n",
       "4  A Class 8 girl became the youngest contestant ...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  staterun life insurance corporation of india l...   \n",
       "1  former congress chief rahul gandhi condoled th...   \n",
       "2  union minister piyush goyal has shared a shark...   \n",
       "3  speaking on figuring out podcast bharatpe cofo...   \n",
       "4  a class 8 girl became the youngest contestant ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  staterun life insur corpor of india lic on sun...   \n",
       "1  former congress chief rahul gandhi condol the ...   \n",
       "2  union minist piyush goyal ha share a shark tan...   \n",
       "3  speak on figur out podcast bharatp cofound ash...   \n",
       "4  a class 8 girl becam the youngest contest to p...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  staterun life insurance corporation of india l...  \n",
       "1  former congress chief rahul gandhi condoled th...  \n",
       "2  union minister piyush goyal ha shared a shark ...  \n",
       "3  speaking on figuring out podcast bharatpe cofo...  \n",
       "4  a class 8 girl became the youngest contestant ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22f49625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform above\n",
    "\n",
    "def cleaners(df, cols_to_keep, col_to_clean):\n",
    "    '''\n",
    "    This function takes in:\n",
    "    - df\n",
    "    - cols_to_keep >> list of columns from the original df to keep\n",
    "    - col_to_clean >> series column that prepare functions will be applied to\n",
    "    and retuns:\n",
    "    a df with the cols_to_keep added to the cleaned, stemmed, and lemmed columns.\n",
    "    '''\n",
    "    df = df[cols_to_keep]\n",
    "    \n",
    "    df['clean'] = df[col_to_clean].apply(basic_clean)\n",
    "    df['stemmed'] = df.clean.apply(stem)\n",
    "    df['lemmatized'] = df.clean.apply(lemmatize)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea2e69e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup Dallas Open House</td>\n",
       "      <td>Come join us for the re-opening of our Dallas ...</td>\n",
       "      <td>come join us for the reopening of our dallas c...</td>\n",
       "      <td>come join us for the reopen of our dalla campu...</td>\n",
       "      <td>come join u for the reopening of our dallas ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Codeup’s Placement Team Continues Setting Records</td>\n",
       "      <td>Our Placement Team is simply defined as a grou...</td>\n",
       "      <td>our placement team is simply defined as a grou...</td>\n",
       "      <td>our placement team is simpli defin as a group ...</td>\n",
       "      <td>our placement team is simply defined a a group...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT Certifications 101: Why They Matter, and Wh...</td>\n",
       "      <td>AWS, Google, Azure, Red Hat, CompTIA…these are...</td>\n",
       "      <td>aws google azure red hat comptiathese are big ...</td>\n",
       "      <td>aw googl azur red hat comptiathes are big name...</td>\n",
       "      <td>aws google azure red hat comptiathese are big ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A rise in cyber attacks means opportunities fo...</td>\n",
       "      <td>In the last few months, the US has experienced...</td>\n",
       "      <td>in the last few months the us has experienced ...</td>\n",
       "      <td>in the last few month the us ha experienc doze...</td>\n",
       "      <td>in the last few month the u ha experienced doz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Use your GI Bill® benefits to Land a Job in Tech</td>\n",
       "      <td>As the end of military service gets closer, ma...</td>\n",
       "      <td>as the end of military service gets closer man...</td>\n",
       "      <td>as the end of militari servic get closer mani ...</td>\n",
       "      <td>a the end of military service get closer many ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                           Codeup Dallas Open House   \n",
       "1  Codeup’s Placement Team Continues Setting Records   \n",
       "2  IT Certifications 101: Why They Matter, and Wh...   \n",
       "3  A rise in cyber attacks means opportunities fo...   \n",
       "4   Use your GI Bill® benefits to Land a Job in Tech   \n",
       "\n",
       "                                             content  \\\n",
       "0  Come join us for the re-opening of our Dallas ...   \n",
       "1  Our Placement Team is simply defined as a grou...   \n",
       "2  AWS, Google, Azure, Red Hat, CompTIA…these are...   \n",
       "3  In the last few months, the US has experienced...   \n",
       "4  As the end of military service gets closer, ma...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  come join us for the reopening of our dallas c...   \n",
       "1  our placement team is simply defined as a grou...   \n",
       "2  aws google azure red hat comptiathese are big ...   \n",
       "3  in the last few months the us has experienced ...   \n",
       "4  as the end of military service gets closer man...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  come join us for the reopen of our dalla campu...   \n",
       "1  our placement team is simpli defin as a group ...   \n",
       "2  aw googl azur red hat comptiathes are big name...   \n",
       "3  in the last few month the us ha experienc doze...   \n",
       "4  as the end of militari servic get closer mani ...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  come join u for the reopening of our dallas ca...  \n",
       "1  our placement team is simply defined a a group...  \n",
       "2  aws google azure red hat comptiathese are big ...  \n",
       "3  in the last few month the u ha experienced doz...  \n",
       "4  a the end of military service get closer many ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaners(codeup_blogs, ['title', 'content'], 'content').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
