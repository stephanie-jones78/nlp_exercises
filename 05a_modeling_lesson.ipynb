{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16df3f0b",
   "metadata": {},
   "source": [
    "# NLP Modeling Lesson\n",
    "\n",
    "In this lesson, we'll do a bit of feature engineering, and then model our text data. We'll be aiming to predict whether a given text message is spam or not, and trying to predict the category of news articles.\n",
    ">### Turning our text data into numeric values we can pass into our model\n",
    "- Our models only see `potatoes`\n",
    "- Finding the hidden trend in our data and using it to make predictions\n",
    "\n",
    "## Feature Extraction: TF-IDF\n",
    "- **TF**: Term Frequency; how often a particular word appears in a document. \n",
    "\n",
    "        \"apple\" appears in this document 15 times\n",
    "- **IDF**: Inverse Document Frequency; a measure of how many (related) documents contain a particular word. \n",
    "\n",
    "        \"apple\" is found in 10 of the 58 documents in our sample\n",
    "        \n",
    "- **TF-IDF**: A combination of the two measures above.\n",
    "\n",
    "### TF: Term Frequency\n",
    "\n",
    "Term frequency can be calculated in a number of ways, all of which reflect how frequently a word appears in a document.\n",
    "\n",
    "- **Raw Count**: This is simply the count of the number of occurances of each word.\n",
    "- **Frequency**: The number of times each word appears divided by the total number of words.\n",
    "- **Augmented Frequency**: The frequency of each word divided by the maximum frequency. This can help prevent bias towards larger documents.\n",
    "\n",
    "Let's take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28767537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from prepare import basic_clean, lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6517ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary had a little lamb, a little lamb, a little lamb.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = 'Mary had a little lamb, a little lamb, a little lamb.'\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ad4c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mary had a little lamb a little lamb a little lamb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up the text, lower and remove punctuation\n",
    "document = document.lower().replace(',', '').replace('.', '')\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711df982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       mary\n",
       "1        had\n",
       "2          a\n",
       "3     little\n",
       "4       lamb\n",
       "5          a\n",
       "6     little\n",
       "7       lamb\n",
       "8          a\n",
       "9     little\n",
       "10      lamb\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform into a series\n",
    "pd.Series(document.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c44f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       mary\n",
       "1        had\n",
       "2          a\n",
       "3     little\n",
       "4       lamb\n",
       "5          a\n",
       "6     little\n",
       "7       lamb\n",
       "8          a\n",
       "9     little\n",
       "10      lamb\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.Series(document.split())\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459169ce",
   "metadata": {},
   "source": [
    "From the series we can extract the value_counts, which is our raw count for term frequency. Once we have the raw counts, we can calculate the other measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d942b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "little    3\n",
       "a         3\n",
       "lamb      3\n",
       "had       1\n",
       "mary      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "784ec879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count\n",
       "little          3\n",
       "a               3\n",
       "lamb            3\n",
       "had             1\n",
       "mary            1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lullaby = pd.DataFrame({'raw_count':words.value_counts()})\n",
    "lullaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04305232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "little    0.272727\n",
       "a         0.272727\n",
       "lamb      0.272727\n",
       "had       0.090909\n",
       "mary      0.090909\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9604b7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count  frequency\n",
       "little          3   0.272727\n",
       "a               3   0.272727\n",
       "lamb            3   0.272727\n",
       "had             1   0.090909\n",
       "mary            1   0.090909"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lullaby['frequency'] = lullaby.raw_count.apply(lambda x: x/lullaby.raw_count.sum())\n",
    "lullaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f496ffd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count  frequency  augmented_frequency\n",
       "little          3   0.272727             1.000000\n",
       "a               3   0.272727             1.000000\n",
       "lamb            3   0.272727             1.000000\n",
       "had             1   0.090909             0.333333\n",
       "mary            1   0.090909             0.333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lullaby['augmented_frequency'] = lullaby.frequency.apply(lambda x: x/lullaby.frequency.max())\n",
    "lullaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3000d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count  frequency  augmented_frequency\n",
       "little          3   0.272727             1.000000\n",
       "a               3   0.272727             1.000000\n",
       "lamb            3   0.272727             1.000000\n",
       "had             1   0.090909             0.333333\n",
       "mary            1   0.090909             0.333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can accomplish the same task using fewer computational resources using .assign\n",
    "(pd.DataFrame({'raw_count': words.value_counts()})\n",
    " .assign(frequency = lambda df: df.raw_count / df.raw_count.sum())\n",
    " .assign(augmented_frequency = lambda df: df.frequency / df.frequency.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fba147",
   "metadata": {},
   "source": [
    "**Takeaways**: These are simply numeric representations of one characteristic of the strings in our corpus (frequency). Aside from simply showing us that some words are more frequent than others, this information by itself doesn't provide us much value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdebed",
   "metadata": {},
   "source": [
    "## IDF: Inverse Document Frequency\n",
    "\n",
    "Inverse Document Frequency also provides information about individual words, but, in order to use this measure, we must have multiple documents, i.e. several different bodies of text.\n",
    "\n",
    "Inverse Document Frequency tells us how much **information** a word provides. \n",
    ">A measurement of the predictive quality of a word. \n",
    "\n",
    "It is based on how commonly a word appears across multiple documents. The metric is divised such that the more frequently a word appears, the lower the IDF for that word will be.\n",
    "\n",
    "      idf(word) = log(# of documents / # of documents containing word)\n",
    "      \n",
    "> If a given word doesn't appear in any documents, the denominator in the equation above would be zero, so some definitions of idf will add 1 to the denominator.\n",
    "\n",
    "For example, imagine we have 20 documents. We can visualize what the idf score looks like with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fac7bc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'IDF for a given word')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_documents = 20\n",
    "\n",
    "x = np.arange(1, n_documents + 1)\n",
    "y = np.log(n_documents / x)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(x, y, marker='.')\n",
    "\n",
    "plt.xticks(x)\n",
    "plt.xlabel('# of Documents the word appears in')\n",
    "plt.ylabel('IDF')\n",
    "plt.title('IDF for a given word')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035fe18",
   "metadata": {},
   "source": [
    "**Takeaways**: Suppose you are trying to create a model that predicts whether a given corpus is written before 1900 or after 1900. If a word appears in every document of your sample, its not going to provide much insight. But if a word only appears in a small number of documents, then it could be representative of an underlying trend (i.e. \"afternoonified\" shows up in a small number of documents all of which were written before 1900).\n",
    "\n",
    "    High IDF = More information\n",
    "\n",
    "Let's look at an example of calculating IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "716fdf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news': 'Codeup announced last thursday that they just launched a new data science program. It is 18 weeks long.',\n",
       " 'description': \"Codeup's data science program teaches hands on skills using Python and pandas.\",\n",
       " 'context': \"Codeup's data science program was created in response to a percieved lack of data science talent, and growing demand.\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our 3 example documents\n",
    "documents = {\n",
    "    'news': 'Codeup announced last thursday that they just launched a new data science program. It is 18 weeks long.',\n",
    "    'description': 'Codeup\\'s data science program teaches hands on skills using Python and pandas.',\n",
    "    'context': 'Codeup\\'s data science program was created in response to a percieved lack of data science talent, and growing demand.'\n",
    "}\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "168c3f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': \"Codeup's data science program was created in response to a \"\n",
      "            'percieved lack of data science talent, and growing demand.',\n",
      " 'description': \"Codeup's data science program teaches hands on skills using \"\n",
      "                'Python and pandas.',\n",
      " 'news': 'Codeup announced last thursday that they just launched a new data '\n",
      "         'science program. It is 18 weeks long.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7389650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning and lemmatizing...\n",
      "\n",
      "{'context': \"codeup's data science program wa created in response to a \"\n",
      "            'percieved lack of data science talent and growing demand',\n",
      " 'description': \"codeup's data science program teach hand on skill using \"\n",
      "                'python and panda',\n",
      " 'news': 'codeup announced last thursday that they just launched a new data '\n",
      "         'science program it is 18 week long'}\n"
     ]
    }
   ],
   "source": [
    "print('\\nCleaning and lemmatizing...\\n')\n",
    "\n",
    "documents = {topic: lemmatize(basic_clean(documents[topic])) for topic in documents}\n",
    "pprint(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2ebbd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['codeup announced last thursday that they just launched a new data science program it is 18 week long', \"codeup's data science program teach hand on skill using python and panda\", \"codeup's data science program wa created in response to a percieved lack of data science talent and growing demand\"])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize document values to help explain our upcoming idf function\n",
    "documents.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d403df",
   "metadata": {},
   "source": [
    "### Note that this function relies on a globally defined documents variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4a39369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word):\n",
    "    '''A simple way to calculate idf for demonstration. Note that this \n",
    "    function relies on a globally defined documents variable.'''\n",
    "    n_occurences = sum([1 for doc in documents.values() if word in doc])\n",
    "    \n",
    "    return len(documents) / n_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5dc36e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['codeup announced last thursday that they just launched a new data science program it is 18 week long', \"codeup's data science program teach hand on skill using python and panda\", \"codeup's data science program wa created in response to a percieved lack of data science talent and growing demand\"])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b19384fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(2 for doc in documents.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "032355f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eadbabed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"codeup announced last thursday that they just launched a new data science program it is 18 week long codeup's data science program teach hand on skill using python and panda codeup's data science program wa created in response to a percieved lack of data science talent and growing demand\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining the elements in the list\n",
    "' '.join(documents.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e90a4c3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['codeup',\n",
       " 'announced',\n",
       " 'last',\n",
       " 'thursday',\n",
       " 'that',\n",
       " 'they',\n",
       " 'just',\n",
       " 'launched',\n",
       " 'a',\n",
       " 'new',\n",
       " 'data',\n",
       " 'science',\n",
       " 'program',\n",
       " 'it',\n",
       " 'is',\n",
       " '18',\n",
       " 'week',\n",
       " 'long',\n",
       " \"codeup's\",\n",
       " 'data',\n",
       " 'science',\n",
       " 'program',\n",
       " 'teach',\n",
       " 'hand',\n",
       " 'on',\n",
       " 'skill',\n",
       " 'using',\n",
       " 'python',\n",
       " 'and',\n",
       " 'panda',\n",
       " \"codeup's\",\n",
       " 'data',\n",
       " 'science',\n",
       " 'program',\n",
       " 'wa',\n",
       " 'created',\n",
       " 'in',\n",
       " 'response',\n",
       " 'to',\n",
       " 'a',\n",
       " 'percieved',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'data',\n",
       " 'science',\n",
       " 'talent',\n",
       " 'and',\n",
       " 'growing',\n",
       " 'demand']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting each word, creating a list of word strings\n",
    "' '.join(documents.values()).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e640334e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['codeup', 'announced', 'last', 'thursday', 'that', 'they', 'just',\n",
       "       'launched', 'a', 'new', 'data', 'science', 'program', 'it', 'is',\n",
       "       '18', 'week', 'long', \"codeup's\", 'teach', 'hand', 'on', 'skill',\n",
       "       'using', 'python', 'and', 'panda', 'wa', 'created', 'in',\n",
       "       'response', 'to', 'percieved', 'lack', 'of', 'talent', 'growing',\n",
       "       'demand'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting each unique string word\n",
    "pd.Series(' '.join(documents.values()).split()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c13182e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['codeup', 'announced', 'last', 'thursday', 'that', 'they', 'just',\n",
       "       'launched', 'a', 'new', 'data', 'science', 'program', 'it', 'is',\n",
       "       '18', 'week', 'long', \"codeup's\", 'teach', 'hand', 'on', 'skill',\n",
       "       'using', 'python', 'and', 'panda', 'wa', 'created', 'in',\n",
       "       'response', 'to', 'percieved', 'lack', 'of', 'talent', 'growing',\n",
       "       'demand'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of the unique words\n",
    "unique_words = pd.Series(' '.join(documents.values()).split()).unique()\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67b0f0ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>announced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>launched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>codeup's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>teach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>using</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>panda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>created</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>percieved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>talent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>growing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>demand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0      codeup\n",
       "1   announced\n",
       "2        last\n",
       "3    thursday\n",
       "4        that\n",
       "5        they\n",
       "6        just\n",
       "7    launched\n",
       "8           a\n",
       "9         new\n",
       "10       data\n",
       "11    science\n",
       "12    program\n",
       "13         it\n",
       "14         is\n",
       "15         18\n",
       "16       week\n",
       "17       long\n",
       "18   codeup's\n",
       "19      teach\n",
       "20       hand\n",
       "21         on\n",
       "22      skill\n",
       "23      using\n",
       "24     python\n",
       "25        and\n",
       "26      panda\n",
       "27         wa\n",
       "28    created\n",
       "29         in\n",
       "30   response\n",
       "31         to\n",
       "32  percieved\n",
       "33       lack\n",
       "34         of\n",
       "35     talent\n",
       "36    growing\n",
       "37     demand"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f9adabb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>announced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>launched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>codeup's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>teach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>using</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>panda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>created</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>percieved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>talent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>growing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>demand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word\n",
       "0      codeup\n",
       "1   announced\n",
       "2        last\n",
       "3    thursday\n",
       "4        that\n",
       "5        they\n",
       "6        just\n",
       "7    launched\n",
       "8           a\n",
       "9         new\n",
       "10       data\n",
       "11    science\n",
       "12    program\n",
       "13         it\n",
       "14         is\n",
       "15         18\n",
       "16       week\n",
       "17       long\n",
       "18   codeup's\n",
       "19      teach\n",
       "20       hand\n",
       "21         on\n",
       "22      skill\n",
       "23      using\n",
       "24     python\n",
       "25        and\n",
       "26      panda\n",
       "27         wa\n",
       "28    created\n",
       "29         in\n",
       "30   response\n",
       "31         to\n",
       "32  percieved\n",
       "33       lack\n",
       "34         of\n",
       "35     talent\n",
       "36    growing\n",
       "37     demand"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dict(word = unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04251c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd928fa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>teach</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>panda</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percieved</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lack</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talent</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growing</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announced</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>launched</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thursday</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codeup's</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codeup</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf\n",
       "word          \n",
       "teach      3.0\n",
       "created    3.0\n",
       "hand       3.0\n",
       "skill      3.0\n",
       "using      3.0\n",
       "python     3.0\n",
       "panda      3.0\n",
       "wa         3.0\n",
       "response   3.0\n",
       "long       3.0\n",
       "to         3.0\n",
       "percieved  3.0\n",
       "lack       3.0\n",
       "of         3.0\n",
       "talent     3.0\n",
       "growing    3.0\n",
       "announced  3.0\n",
       "demand     3.0\n",
       "new        3.0\n",
       "launched   3.0\n",
       "18         3.0\n",
       "last       3.0\n",
       "is         3.0\n",
       "it         3.0\n",
       "thursday   3.0\n",
       "that       3.0\n",
       "they       3.0\n",
       "just       3.0\n",
       "week       3.0\n",
       "codeup's   1.5\n",
       "in         1.5\n",
       "and        1.5\n",
       "a          1.0\n",
       "data       1.0\n",
       "science    1.0\n",
       "program    1.0\n",
       "on         1.0\n",
       "codeup     1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the unique words into a data frame\n",
    "(pd.DataFrame(dict(word=unique_words))\n",
    " # calculate the idf for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # sort the data for presentation purposes\n",
    " .set_index('word')\n",
    " .sort_values(by='idf', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23001665",
   "metadata": {},
   "source": [
    "**Takeaways**: Words with the lowest IDF score were found in every document. They do us no good in helping us to distinguish whether a given corpus was \"context\", \"description\", or \"news\". Words with high IDF scores are more strongly linked to a particular classification. \n",
    "\n",
    "But this sample is so small that we should be cautious in using the word \"on\" as a means to classify a future corpus. \n",
    "\n",
    "> The calculation for an individual IDF score requires a word **and** a set of documents.\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "TF-IDF is simply the multiplication of the two metrics we've discussed above. Let's calculate an TF-IDF for all of the words and documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5bd75de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('news', 'codeup announced last thursday that they just launched a new data science program it is 18 week long'), ('description', \"codeup's data science program teach hand on skill using python and panda\"), ('context', \"codeup's data science program wa created in response to a percieved lack of data science talent and growing demand\")])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will create an empty list to store values for us as we iterate through our data\n",
    "tfs = []\n",
    "\n",
    "# Start by iterating over all the documents. We can use .items() to speed up our loop:\n",
    "documents.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc91974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a for loop\n",
    "for doc, text in documents.items():\n",
    "    # We will make a dataframe that contains the term frequency for every word\n",
    "    df = (pd.Series(text.split())\n",
    "          .value_counts()\n",
    "          .reset_index()\n",
    "          .set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
    "          .assign(tf=lambda df: df.raw_count / df.shape[0])\n",
    "          .drop(columns='raw_count')\n",
    "          .assign(doc=doc))\n",
    "    # Then add that data frame to our list\n",
    "    tfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ea039e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         word        tf   doc\n",
       " 0     science  0.055556  news\n",
       " 1     program  0.055556  news\n",
       " 2         new  0.055556  news\n",
       " 3          is  0.055556  news\n",
       " 4    launched  0.055556  news\n",
       " 5      codeup  0.055556  news\n",
       " 6        week  0.055556  news\n",
       " 7        last  0.055556  news\n",
       " 8   announced  0.055556  news\n",
       " 9    thursday  0.055556  news\n",
       " 10         it  0.055556  news\n",
       " 11       just  0.055556  news\n",
       " 12         18  0.055556  news\n",
       " 13       long  0.055556  news\n",
       " 14       data  0.055556  news\n",
       " 15       that  0.055556  news\n",
       " 16          a  0.055556  news\n",
       " 17       they  0.055556  news,\n",
       "         word        tf          doc\n",
       " 0    science  0.083333  description\n",
       " 1    program  0.083333  description\n",
       " 2        and  0.083333  description\n",
       " 3       hand  0.083333  description\n",
       " 4       data  0.083333  description\n",
       " 5         on  0.083333  description\n",
       " 6      skill  0.083333  description\n",
       " 7   codeup's  0.083333  description\n",
       " 8      using  0.083333  description\n",
       " 9      panda  0.083333  description\n",
       " 10    python  0.083333  description\n",
       " 11     teach  0.083333  description,\n",
       "          word        tf      doc\n",
       " 0     science  0.117647  context\n",
       " 1        data  0.117647  context\n",
       " 2          in  0.058824  context\n",
       " 3     created  0.058824  context\n",
       " 4     growing  0.058824  context\n",
       " 5          wa  0.058824  context\n",
       " 6      demand  0.058824  context\n",
       " 7         and  0.058824  context\n",
       " 8      talent  0.058824  context\n",
       " 9        lack  0.058824  context\n",
       " 10    program  0.058824  context\n",
       " 11         of  0.058824  context\n",
       " 12   codeup's  0.058824  context\n",
       " 13  percieved  0.058824  context\n",
       " 14   response  0.058824  context\n",
       " 15          a  0.058824  context\n",
       " 16         to  0.058824  context]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e19375ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING LOOP\n",
      "\n",
      "\n",
      "Text being manipulated:\n",
      "-----------------------------------------\n",
      "Document: news\n",
      "Text: codeup announced last thursday that they just launched a new data science program it is 18 week long\n",
      "\n",
      "\n",
      "Step 1: Splitting the corpus into a list of words\n",
      "df = (pd.Series(text.split()))\n",
      "-----------------------------------------\n",
      "0        codeup\n",
      "1     announced\n",
      "2          last\n",
      "3      thursday\n",
      "4          that\n",
      "5          they\n",
      "6          just\n",
      "7      launched\n",
      "8             a\n",
      "9           new\n",
      "10         data\n",
      "11      science\n",
      "12      program\n",
      "13           it\n",
      "14           is\n",
      "15           18\n",
      "16         week\n",
      "17         long\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Step 2: Converting list of words into a value count array\n",
      "df = df.value_counts()\n",
      "-----------------------------------------\n",
      "science      1\n",
      "program      1\n",
      "new          1\n",
      "is           1\n",
      "launched     1\n",
      "codeup       1\n",
      "week         1\n",
      "last         1\n",
      "announced    1\n",
      "thursday     1\n",
      "it           1\n",
      "just         1\n",
      "18           1\n",
      "long         1\n",
      "data         1\n",
      "that         1\n",
      "a            1\n",
      "they         1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Step 3: Resetting the index\n",
      "df = df.reset_index()\n",
      "-----------------------------------------\n",
      "        index  0\n",
      "0     science  1\n",
      "1     program  1\n",
      "2         new  1\n",
      "3          is  1\n",
      "4    launched  1\n",
      "5      codeup  1\n",
      "6        week  1\n",
      "7        last  1\n",
      "8   announced  1\n",
      "9    thursday  1\n",
      "10         it  1\n",
      "11       just  1\n",
      "12         18  1\n",
      "13       long  1\n",
      "14       data  1\n",
      "15       that  1\n",
      "16          a  1\n",
      "17       they  1\n",
      "\n",
      "\n",
      "Step 4: Relabeling the columns\n",
      "df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
      "-----------------------------------------\n",
      "         word  raw_count\n",
      "0     science          1\n",
      "1     program          1\n",
      "2         new          1\n",
      "3          is          1\n",
      "4    launched          1\n",
      "5      codeup          1\n",
      "6        week          1\n",
      "7        last          1\n",
      "8   announced          1\n",
      "9    thursday          1\n",
      "10         it          1\n",
      "11       just          1\n",
      "12         18          1\n",
      "13       long          1\n",
      "14       data          1\n",
      "15       that          1\n",
      "16          a          1\n",
      "17       they          1\n",
      "\n",
      "\n",
      "Step 5: Calculating the Term Frequency of Each Word within this one corpus\n",
      "df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
      "-----------------------------------------\n",
      "         word  raw_count        tf\n",
      "0     science          1  0.055556\n",
      "1     program          1  0.055556\n",
      "2         new          1  0.055556\n",
      "3          is          1  0.055556\n",
      "4    launched          1  0.055556\n",
      "5      codeup          1  0.055556\n",
      "6        week          1  0.055556\n",
      "7        last          1  0.055556\n",
      "8   announced          1  0.055556\n",
      "9    thursday          1  0.055556\n",
      "10         it          1  0.055556\n",
      "11       just          1  0.055556\n",
      "12         18          1  0.055556\n",
      "13       long          1  0.055556\n",
      "14       data          1  0.055556\n",
      "15       that          1  0.055556\n",
      "16          a          1  0.055556\n",
      "17       they          1  0.055556\n",
      "\n",
      "\n",
      "Step 6: Dropping the 'raw_count' column\n",
      "df = df.drop(columns='raw_count')\n",
      "-----------------------------------------\n",
      "         word        tf\n",
      "0     science  0.055556\n",
      "1     program  0.055556\n",
      "2         new  0.055556\n",
      "3          is  0.055556\n",
      "4    launched  0.055556\n",
      "5      codeup  0.055556\n",
      "6        week  0.055556\n",
      "7        last  0.055556\n",
      "8   announced  0.055556\n",
      "9    thursday  0.055556\n",
      "10         it  0.055556\n",
      "11       just  0.055556\n",
      "12         18  0.055556\n",
      "13       long  0.055556\n",
      "14       data  0.055556\n",
      "15       that  0.055556\n",
      "16          a  0.055556\n",
      "17       they  0.055556\n",
      "\n",
      "\n",
      "Step 6: Adding the document label for this corpus\n",
      "df['doc'] = doc\n",
      "-----------------------------------------\n",
      "         word        tf   doc\n",
      "0     science  0.055556  news\n",
      "1     program  0.055556  news\n",
      "2         new  0.055556  news\n",
      "3          is  0.055556  news\n",
      "4    launched  0.055556  news\n",
      "5      codeup  0.055556  news\n",
      "6        week  0.055556  news\n",
      "7        last  0.055556  news\n",
      "8   announced  0.055556  news\n",
      "9    thursday  0.055556  news\n",
      "10         it  0.055556  news\n",
      "11       just  0.055556  news\n",
      "12         18  0.055556  news\n",
      "13       long  0.055556  news\n",
      "14       data  0.055556  news\n",
      "15       that  0.055556  news\n",
      "16          a  0.055556  news\n",
      "17       they  0.055556  news\n",
      "\n",
      "\n",
      "ITERATION OF ELEMENT COMPLETE\n",
      "\n",
      " \n",
      "\n",
      "Text being manipulated:\n",
      "-----------------------------------------\n",
      "Document: description\n",
      "Text: codeup's data science program teach hand on skill using python and panda\n",
      "\n",
      "\n",
      "Step 1: Splitting the corpus into a list of words\n",
      "df = (pd.Series(text.split()))\n",
      "-----------------------------------------\n",
      "0     codeup's\n",
      "1         data\n",
      "2      science\n",
      "3      program\n",
      "4        teach\n",
      "5         hand\n",
      "6           on\n",
      "7        skill\n",
      "8        using\n",
      "9       python\n",
      "10         and\n",
      "11       panda\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Step 2: Converting list of words into a value count array\n",
      "df = df.value_counts()\n",
      "-----------------------------------------\n",
      "science     1\n",
      "program     1\n",
      "and         1\n",
      "hand        1\n",
      "data        1\n",
      "on          1\n",
      "skill       1\n",
      "codeup's    1\n",
      "using       1\n",
      "panda       1\n",
      "python      1\n",
      "teach       1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Step 3: Resetting the index\n",
      "df = df.reset_index()\n",
      "-----------------------------------------\n",
      "       index  0\n",
      "0    science  1\n",
      "1    program  1\n",
      "2        and  1\n",
      "3       hand  1\n",
      "4       data  1\n",
      "5         on  1\n",
      "6      skill  1\n",
      "7   codeup's  1\n",
      "8      using  1\n",
      "9      panda  1\n",
      "10    python  1\n",
      "11     teach  1\n",
      "\n",
      "\n",
      "Step 4: Relabeling the columns\n",
      "df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
      "-----------------------------------------\n",
      "        word  raw_count\n",
      "0    science          1\n",
      "1    program          1\n",
      "2        and          1\n",
      "3       hand          1\n",
      "4       data          1\n",
      "5         on          1\n",
      "6      skill          1\n",
      "7   codeup's          1\n",
      "8      using          1\n",
      "9      panda          1\n",
      "10    python          1\n",
      "11     teach          1\n",
      "\n",
      "\n",
      "Step 5: Calculating the Term Frequency of Each Word within this one corpus\n",
      "df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
      "-----------------------------------------\n",
      "        word  raw_count        tf\n",
      "0    science          1  0.083333\n",
      "1    program          1  0.083333\n",
      "2        and          1  0.083333\n",
      "3       hand          1  0.083333\n",
      "4       data          1  0.083333\n",
      "5         on          1  0.083333\n",
      "6      skill          1  0.083333\n",
      "7   codeup's          1  0.083333\n",
      "8      using          1  0.083333\n",
      "9      panda          1  0.083333\n",
      "10    python          1  0.083333\n",
      "11     teach          1  0.083333\n",
      "\n",
      "\n",
      "Step 6: Dropping the 'raw_count' column\n",
      "df = df.drop(columns='raw_count')\n",
      "-----------------------------------------\n",
      "        word        tf\n",
      "0    science  0.083333\n",
      "1    program  0.083333\n",
      "2        and  0.083333\n",
      "3       hand  0.083333\n",
      "4       data  0.083333\n",
      "5         on  0.083333\n",
      "6      skill  0.083333\n",
      "7   codeup's  0.083333\n",
      "8      using  0.083333\n",
      "9      panda  0.083333\n",
      "10    python  0.083333\n",
      "11     teach  0.083333\n",
      "\n",
      "\n",
      "Step 6: Adding the document label for this corpus\n",
      "df['doc'] = doc\n",
      "-----------------------------------------\n",
      "        word        tf          doc\n",
      "0    science  0.083333  description\n",
      "1    program  0.083333  description\n",
      "2        and  0.083333  description\n",
      "3       hand  0.083333  description\n",
      "4       data  0.083333  description\n",
      "5         on  0.083333  description\n",
      "6      skill  0.083333  description\n",
      "7   codeup's  0.083333  description\n",
      "8      using  0.083333  description\n",
      "9      panda  0.083333  description\n",
      "10    python  0.083333  description\n",
      "11     teach  0.083333  description\n",
      "\n",
      "\n",
      "ITERATION OF ELEMENT COMPLETE\n",
      "\n",
      " \n",
      "\n",
      "Text being manipulated:\n",
      "-----------------------------------------\n",
      "Document: context\n",
      "Text: codeup's data science program wa created in response to a percieved lack of data science talent and growing demand\n",
      "\n",
      "\n",
      "Step 1: Splitting the corpus into a list of words\n",
      "df = (pd.Series(text.split()))\n",
      "-----------------------------------------\n",
      "0      codeup's\n",
      "1          data\n",
      "2       science\n",
      "3       program\n",
      "4            wa\n",
      "5       created\n",
      "6            in\n",
      "7      response\n",
      "8            to\n",
      "9             a\n",
      "10    percieved\n",
      "11         lack\n",
      "12           of\n",
      "13         data\n",
      "14      science\n",
      "15       talent\n",
      "16          and\n",
      "17      growing\n",
      "18       demand\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Step 2: Converting list of words into a value count array\n",
      "df = df.value_counts()\n",
      "-----------------------------------------\n",
      "science      2\n",
      "data         2\n",
      "in           1\n",
      "created      1\n",
      "growing      1\n",
      "wa           1\n",
      "demand       1\n",
      "and          1\n",
      "talent       1\n",
      "lack         1\n",
      "program      1\n",
      "of           1\n",
      "codeup's     1\n",
      "percieved    1\n",
      "response     1\n",
      "a            1\n",
      "to           1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Step 3: Resetting the index\n",
      "df = df.reset_index()\n",
      "-----------------------------------------\n",
      "        index  0\n",
      "0     science  2\n",
      "1        data  2\n",
      "2          in  1\n",
      "3     created  1\n",
      "4     growing  1\n",
      "5          wa  1\n",
      "6      demand  1\n",
      "7         and  1\n",
      "8      talent  1\n",
      "9        lack  1\n",
      "10    program  1\n",
      "11         of  1\n",
      "12   codeup's  1\n",
      "13  percieved  1\n",
      "14   response  1\n",
      "15          a  1\n",
      "16         to  1\n",
      "\n",
      "\n",
      "Step 4: Relabeling the columns\n",
      "df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
      "-----------------------------------------\n",
      "         word  raw_count\n",
      "0     science          2\n",
      "1        data          2\n",
      "2          in          1\n",
      "3     created          1\n",
      "4     growing          1\n",
      "5          wa          1\n",
      "6      demand          1\n",
      "7         and          1\n",
      "8      talent          1\n",
      "9        lack          1\n",
      "10    program          1\n",
      "11         of          1\n",
      "12   codeup's          1\n",
      "13  percieved          1\n",
      "14   response          1\n",
      "15          a          1\n",
      "16         to          1\n",
      "\n",
      "\n",
      "Step 5: Calculating the Term Frequency of Each Word within this one corpus\n",
      "df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
      "-----------------------------------------\n",
      "         word  raw_count        tf\n",
      "0     science          2  0.117647\n",
      "1        data          2  0.117647\n",
      "2          in          1  0.058824\n",
      "3     created          1  0.058824\n",
      "4     growing          1  0.058824\n",
      "5          wa          1  0.058824\n",
      "6      demand          1  0.058824\n",
      "7         and          1  0.058824\n",
      "8      talent          1  0.058824\n",
      "9        lack          1  0.058824\n",
      "10    program          1  0.058824\n",
      "11         of          1  0.058824\n",
      "12   codeup's          1  0.058824\n",
      "13  percieved          1  0.058824\n",
      "14   response          1  0.058824\n",
      "15          a          1  0.058824\n",
      "16         to          1  0.058824\n",
      "\n",
      "\n",
      "Step 6: Dropping the 'raw_count' column\n",
      "df = df.drop(columns='raw_count')\n",
      "-----------------------------------------\n",
      "         word        tf\n",
      "0     science  0.117647\n",
      "1        data  0.117647\n",
      "2          in  0.058824\n",
      "3     created  0.058824\n",
      "4     growing  0.058824\n",
      "5          wa  0.058824\n",
      "6      demand  0.058824\n",
      "7         and  0.058824\n",
      "8      talent  0.058824\n",
      "9        lack  0.058824\n",
      "10    program  0.058824\n",
      "11         of  0.058824\n",
      "12   codeup's  0.058824\n",
      "13  percieved  0.058824\n",
      "14   response  0.058824\n",
      "15          a  0.058824\n",
      "16         to  0.058824\n",
      "\n",
      "\n",
      "Step 6: Adding the document label for this corpus\n",
      "df['doc'] = doc\n",
      "-----------------------------------------\n",
      "         word        tf      doc\n",
      "0     science  0.117647  context\n",
      "1        data  0.117647  context\n",
      "2          in  0.058824  context\n",
      "3     created  0.058824  context\n",
      "4     growing  0.058824  context\n",
      "5          wa  0.058824  context\n",
      "6      demand  0.058824  context\n",
      "7         and  0.058824  context\n",
      "8      talent  0.058824  context\n",
      "9        lack  0.058824  context\n",
      "10    program  0.058824  context\n",
      "11         of  0.058824  context\n",
      "12   codeup's  0.058824  context\n",
      "13  percieved  0.058824  context\n",
      "14   response  0.058824  context\n",
      "15          a  0.058824  context\n",
      "16         to  0.058824  context\n",
      "\n",
      "\n",
      "ITERATION OF ELEMENT COMPLETE\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What actually happened in that code block? Overexplanation using print statements:\n",
    "print(\"BEGINNING LOOP\")\n",
    "print(\"\\n\")\n",
    "for doc, text in documents.items():\n",
    "    print(\"Text being manipulated:\")\n",
    "    print('-----------------------------------------')\n",
    "    print(f'Document: {doc}')\n",
    "    print(f'Text: {text}')\n",
    "    print('\\n')\n",
    "    print(\"Step 1: Splitting the corpus into a list of words\")\n",
    "    print(\"df = (pd.Series(text.split()))\")\n",
    "    print('-----------------------------------------')\n",
    "    df = (pd.Series(text.split()))\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 2: Converting list of words into a value count array\")\n",
    "    print(\"df = df.value_counts()\")\n",
    "    print('-----------------------------------------')\n",
    "    df = df.value_counts()\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 3: Resetting the index\")\n",
    "    print(\"df = df.reset_index()\")\n",
    "    print('-----------------------------------------')\n",
    "    df = df.reset_index()\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 4: Relabeling the columns\")\n",
    "    print(\"df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\")\n",
    "    print('-----------------------------------------')    \n",
    "    df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
    "    print(df)\n",
    "    print('\\n')    \n",
    "    \n",
    "    print(\"Step 5: Calculating the Term Frequency of Each Word within this one corpus\")\n",
    "    print(\"df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\")\n",
    "    print('-----------------------------------------')      \n",
    "    df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 6: Dropping the 'raw_count' column\")\n",
    "    print(\"df = df.drop(columns='raw_count')\")\n",
    "    print('-----------------------------------------')      \n",
    "    df = df.drop(columns='raw_count')\n",
    "    print(df)\n",
    "    print('\\n')    \n",
    "    \n",
    "    print(\"Step 6: Adding the document label for this corpus\")\n",
    "    print(\"df['doc'] = doc\")\n",
    "    print('-----------------------------------------') \n",
    "    df['doc'] = doc\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    print(\"ITERATION OF ELEMENT COMPLETE\")\n",
    "    print('\\n', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2059a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         word        tf   doc\n",
       " 0     science  0.055556  news\n",
       " 1     program  0.055556  news\n",
       " 2         new  0.055556  news\n",
       " 3          is  0.055556  news\n",
       " 4    launched  0.055556  news\n",
       " 5      codeup  0.055556  news\n",
       " 6        week  0.055556  news\n",
       " 7        last  0.055556  news\n",
       " 8   announced  0.055556  news\n",
       " 9    thursday  0.055556  news\n",
       " 10         it  0.055556  news\n",
       " 11       just  0.055556  news\n",
       " 12         18  0.055556  news\n",
       " 13       long  0.055556  news\n",
       " 14       data  0.055556  news\n",
       " 15       that  0.055556  news\n",
       " 16          a  0.055556  news\n",
       " 17       they  0.055556  news,\n",
       "         word        tf          doc\n",
       " 0    science  0.083333  description\n",
       " 1    program  0.083333  description\n",
       " 2        and  0.083333  description\n",
       " 3       hand  0.083333  description\n",
       " 4       data  0.083333  description\n",
       " 5         on  0.083333  description\n",
       " 6      skill  0.083333  description\n",
       " 7   codeup's  0.083333  description\n",
       " 8      using  0.083333  description\n",
       " 9      panda  0.083333  description\n",
       " 10    python  0.083333  description\n",
       " 11     teach  0.083333  description,\n",
       "          word        tf      doc\n",
       " 0     science  0.117647  context\n",
       " 1        data  0.117647  context\n",
       " 2          in  0.058824  context\n",
       " 3     created  0.058824  context\n",
       " 4     growing  0.058824  context\n",
       " 5          wa  0.058824  context\n",
       " 6      demand  0.058824  context\n",
       " 7         and  0.058824  context\n",
       " 8      talent  0.058824  context\n",
       " 9        lack  0.058824  context\n",
       " 10    program  0.058824  context\n",
       " 11         of  0.058824  context\n",
       " 12   codeup's  0.058824  context\n",
       " 13  percieved  0.058824  context\n",
       " 14   response  0.058824  context\n",
       " 15          a  0.058824  context\n",
       " 16         to  0.058824  context]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "494a7ce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>doc</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teach</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>python</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>panda</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>using</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skill</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hand</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>to</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>percieved</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>growing</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>created</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>talent</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lack</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>demand</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>of</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wa</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>response</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>announced</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>new</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>is</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>launched</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>week</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>last</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>that</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>long</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>thursday</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>it</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>just</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>they</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>and</td>\n",
       "      <td>description</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>codeup's</td>\n",
       "      <td>description</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>science</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>data</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>and</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>in</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>codeup's</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>on</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>data</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>program</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>science</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>program</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>a</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>program</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>a</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>data</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>codeup</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>science</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word          doc    tf_idf\n",
       "0       teach  description  0.250000\n",
       "1      python  description  0.250000\n",
       "2       panda  description  0.250000\n",
       "3       using  description  0.250000\n",
       "4       skill  description  0.250000\n",
       "5        hand  description  0.250000\n",
       "6          to      context  0.176471\n",
       "7   percieved      context  0.176471\n",
       "8     growing      context  0.176471\n",
       "9     created      context  0.176471\n",
       "10     talent      context  0.176471\n",
       "11       lack      context  0.176471\n",
       "12     demand      context  0.176471\n",
       "13         of      context  0.176471\n",
       "14         wa      context  0.176471\n",
       "15   response      context  0.176471\n",
       "16  announced         news  0.166667\n",
       "17        new         news  0.166667\n",
       "18         is         news  0.166667\n",
       "19   launched         news  0.166667\n",
       "20       week         news  0.166667\n",
       "21       last         news  0.166667\n",
       "22       that         news  0.166667\n",
       "23       long         news  0.166667\n",
       "24   thursday         news  0.166667\n",
       "25         it         news  0.166667\n",
       "26       just         news  0.166667\n",
       "27         18         news  0.166667\n",
       "28       they         news  0.166667\n",
       "29        and  description  0.125000\n",
       "30   codeup's  description  0.125000\n",
       "31    science      context  0.117647\n",
       "32       data      context  0.117647\n",
       "33        and      context  0.088235\n",
       "34         in      context  0.088235\n",
       "35   codeup's      context  0.088235\n",
       "36         on  description  0.083333\n",
       "37       data  description  0.083333\n",
       "38    program  description  0.083333\n",
       "39    science  description  0.083333\n",
       "40    program      context  0.058824\n",
       "41          a      context  0.058824\n",
       "42    program         news  0.055556\n",
       "43          a         news  0.055556\n",
       "44       data         news  0.055556\n",
       "45     codeup         news  0.055556\n",
       "46    science         news  0.055556"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll then concatenate all the tf values together.\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the if and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False)\n",
    " .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a945e1b",
   "metadata": {},
   "source": [
    "It's more common to see the data presented with the words as features, and the documents as observations, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5352734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF for each word/doc combination\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>18</th>\n",
       "      <th>a</th>\n",
       "      <th>and</th>\n",
       "      <th>announced</th>\n",
       "      <th>codeup</th>\n",
       "      <th>codeup's</th>\n",
       "      <th>created</th>\n",
       "      <th>data</th>\n",
       "      <th>demand</th>\n",
       "      <th>growing</th>\n",
       "      <th>...</th>\n",
       "      <th>skill</th>\n",
       "      <th>talent</th>\n",
       "      <th>teach</th>\n",
       "      <th>that</th>\n",
       "      <th>they</th>\n",
       "      <th>thursday</th>\n",
       "      <th>to</th>\n",
       "      <th>using</th>\n",
       "      <th>wa</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word               18         a       and  announced    codeup  codeup's  \\\n",
       "doc                                                                        \n",
       "context      0.000000  0.058824  0.088235   0.000000  0.000000  0.088235   \n",
       "description  0.000000  0.000000  0.125000   0.000000  0.000000  0.125000   \n",
       "news         0.166667  0.055556  0.000000   0.166667  0.055556  0.000000   \n",
       "\n",
       "word          created      data    demand   growing  ...  skill    talent  \\\n",
       "doc                                                  ...                    \n",
       "context      0.176471  0.117647  0.176471  0.176471  ...   0.00  0.176471   \n",
       "description  0.000000  0.083333  0.000000  0.000000  ...   0.25  0.000000   \n",
       "news         0.000000  0.055556  0.000000  0.000000  ...   0.00  0.000000   \n",
       "\n",
       "word         teach      that      they  thursday        to  using        wa  \\\n",
       "doc                                                                           \n",
       "context       0.00  0.000000  0.000000  0.000000  0.176471   0.00  0.176471   \n",
       "description   0.25  0.000000  0.000000  0.000000  0.000000   0.25  0.000000   \n",
       "news          0.00  0.166667  0.166667  0.166667  0.000000   0.00  0.000000   \n",
       "\n",
       "word             week  \n",
       "doc                    \n",
       "context      0.000000  \n",
       "description  0.000000  \n",
       "news         0.166667  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll then concatenate all the tf values together.\n",
    "print(\"TF-IDF for each word/doc combination\")\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the if and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False)\n",
    " .pipe(lambda df: pd.crosstab(df.doc, df.word, values=df.tf_idf, aggfunc=lambda x: x))\n",
    " .fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb2dd7a",
   "metadata": {},
   "source": [
    "## TF-IDF with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2061d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x36 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# creating tf-idf object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# applying object\n",
    "tfidfs = tfidf.fit_transform(documents.values())\n",
    "tfidfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c0e1d",
   "metadata": {},
   "source": [
    "We get back a sparse matrix, a matrix with more 0s than anything else. Numpy has a special type that makes some manipulations and operations faster on sparse matrices.\n",
    "\n",
    "Becuase our data set is pretty small, we can convert our sparse matrix to a regular one, and put everything in a dataframe. If our data were larger, the operation below might take much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e094dc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>and</th>\n",
       "      <th>announced</th>\n",
       "      <th>codeup</th>\n",
       "      <th>created</th>\n",
       "      <th>data</th>\n",
       "      <th>demand</th>\n",
       "      <th>growing</th>\n",
       "      <th>hand</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>skill</th>\n",
       "      <th>talent</th>\n",
       "      <th>teach</th>\n",
       "      <th>that</th>\n",
       "      <th>they</th>\n",
       "      <th>thursday</th>\n",
       "      <th>to</th>\n",
       "      <th>using</th>\n",
       "      <th>wa</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.155666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152159</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.304317</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         18       and  announced    codeup   created      data    demand  \\\n",
       "0  0.263566  0.000000   0.263566  0.155666  0.000000  0.155666  0.000000   \n",
       "1  0.000000  0.253880   0.000000  0.197160  0.000000  0.197160  0.000000   \n",
       "2  0.000000  0.195932   0.000000  0.152159  0.257627  0.304317  0.257627   \n",
       "\n",
       "    growing      hand        in  ...     skill    talent     teach      that  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.263566   \n",
       "1  0.000000  0.333821  0.000000  ...  0.333821  0.000000  0.333821  0.000000   \n",
       "2  0.257627  0.000000  0.257627  ...  0.000000  0.257627  0.000000  0.000000   \n",
       "\n",
       "       they  thursday        to     using        wa      week  \n",
       "0  0.263566  0.263566  0.000000  0.000000  0.000000  0.263566  \n",
       "1  0.000000  0.000000  0.000000  0.333821  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.257627  0.000000  0.257627  0.000000  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidfs.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0762a2",
   "metadata": {},
   "source": [
    "Why are the values different? Because in our manual version we used a simplified formula. Scikit-learn uses the proper IDF formula to calculate TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1f038",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Now we'll use the computed TF-IDF values as features in a model. We'll take a look at the spam data set first.\n",
    "\n",
    "Because of the way we are modeling the data, we have a lot of columns, and it is not uncommon to have more columns than rows. Also, our data is very imbalanced in the class distribution, that is, there are many more ham messages than spam messages.\n",
    "\n",
    "Other than these considerations, we can treat this as a standard classification problem. We'll use logistic regression as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd049f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# regression model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# evaluation metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# accessing db\n",
    "from env import user, password, host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9cb70e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "id                                                         \n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acquiring ham/spam data\n",
    "def get_db_url(database, host=host, user=user, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{database}'\n",
    "\n",
    "url = get_db_url(\"spam_db\")\n",
    "sql = \"SELECT * FROM spam\"\n",
    "\n",
    "df = pd.read_sql(sql, url, index_col=\"id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e35483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tfidf object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# creating X and y split with text as numerical values\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5952c72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4457x8672 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 59043 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1fece5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4457 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual\n",
       "id         \n",
       "1264    ham\n",
       "4559    ham\n",
       "549     ham\n",
       "3374    ham\n",
       "452     ham\n",
       "...     ...\n",
       "3471    ham\n",
       "4153    ham\n",
       "3922    ham\n",
       "2723    ham\n",
       "1421    ham\n",
       "\n",
       "[4457 rows x 1 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a24b141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5073</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual\n",
       "id         \n",
       "4954    ham\n",
       "5      spam\n",
       "439     ham\n",
       "5073    ham\n",
       "3997   spam\n",
       "...     ...\n",
       "5250   spam\n",
       "3068    ham\n",
       "1880    ham\n",
       "255     ham\n",
       "1728    ham\n",
       "\n",
       "[1115 rows x 1 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8112d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model object\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# train predictions\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "# test predictions\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9328dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual predicted\n",
       "id                   \n",
       "1264    ham       ham\n",
       "4559    ham       ham\n",
       "549     ham       ham\n",
       "3374    ham       ham\n",
       "452     ham       ham"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae72be95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5073</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual predicted\n",
       "id                   \n",
       "4954    ham       ham\n",
       "5      spam       ham\n",
       "439     ham       ham\n",
       "5073    ham       ham\n",
       "3997   spam      spam"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae14f2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.60%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3857   105\n",
      "spam          2   493\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       1.00      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.98      0.98      0.98      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation metrics for train\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96c3bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.98%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        965    55\n",
      "spam         1    94\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.97       966\n",
      "        spam       0.99      0.63      0.77       149\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.97      0.81      0.87      1115\n",
      "weighted avg       0.95      0.95      0.94      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation metrics for test\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b30e5",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Do your work for this exercise in a file named `model.ipynb`.\n",
    "\n",
    "Take the work we did in the lessons further:\n",
    "\n",
    "1. What other types of models (i.e. different classifcation algorithms) could you use? Create a model with a different algorithm.\n",
    "2. How do the models compare when trained on term frequency data alone, instead of TF-IDF values?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
